{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "import rasterio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from rasterio.mask import mask\n",
    "from rasterio.plot import show\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from osgeo import gdal\n",
    "import ee\n",
    "\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "\n",
    "import rioxarray as rxr\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get project root (adjust based on your folder depth)\n",
    "current_dir = Path(os.getcwd())\n",
    "project_root = current_dir.parent.parent  # Navigate up from \"Scripts/Phase1_Data_Preprocessing\"\n",
    "\n",
    "with open(project_root / \"config.yml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "\n",
    "raw_data_dir = project_root / config[\"paths\"][\"raw_data\"]\n",
    "era5_raw_path = raw_data_dir / config[\"paths\"][\"era5_raw\"]\n",
    "\n",
    "# Processed data paths\n",
    "processed_data_dir = project_root / config[\"paths\"][\"processed_data\"]\n",
    "soil_processed_dir = processed_data_dir / \"GIS/Soil\"\n",
    "output_dir = processed_data_dir / \"GIS/Study_Area_Boundary\"\n",
    "output_path = output_dir / \"Tadla_plain_common.shp\"\n",
    "tadla_common_path = processed_data_dir / config[\"paths\"][\"tadla_boundary_processed\"]\n",
    "soil_processed_path = processed_data_dir / config[\"paths\"][\"soil_processed\"]\n",
    "dem_processed_path = processed_data_dir / config[\"paths\"][\"dem_processed\"]\n",
    "slope_path = processed_data_dir / \"GIS/Topography/tadla_slope.tif\"\n",
    "aspect_path = processed_data_dir / \"GIS/Topography/tadla_aspect.tif\"\n",
    "chirps_processed_path = processed_data_dir / config[\"paths\"][\"chirps_processed\"]\n",
    "era5_processed_path = processed_data_dir / config[\"paths\"][\"era5_processed\"]\n",
    "wv0010_processed_path = processed_data_dir / config[\"paths\"][\"wv0010_processed\"]\n",
    "topography_processed_dir = processed_data_dir / \"GIS/Topography\"\n",
    "\n",
    "land_use_processed_dir = processed_data_dir / config[\"paths\"][\"land_use_processed\"]\n",
    "\n",
    "weather_processed_dir = processed_data_dir / \"Weather\"\n",
    "chirps_output_dir = Path(config[\"paths\"][\"chirps_dir\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Spatial Alignment Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_spatial_alignment(reference_path):\n",
    "    \"\"\"Check CRS, resolution, and transform across all datasets.\"\"\"\n",
    "    ref = rasterio.open(reference_path)\n",
    "    layers = [\n",
    "        Path(soil_processed_dir / \"tadla_clay_10m.tif\"),\n",
    "        Path(dem_processed_path),\n",
    "        Path(land_use_processed_dir / \"Sentinel2_Tadla_NDVI_2023.tif\"),\n",
    "        Path(weather_processed_dir / \"CHIRPS_Annual/CHIRPS_2023_reproj.tif\"),\n",
    "        Path(weather_processed_dir / \"ERA5_Annual/ERA5_2023_reproj.tif\")\n",
    "    ]\n",
    "    \n",
    "    print(\"=== Spatial Alignment Check ===\")\n",
    "    for layer in layers:\n",
    "        with rasterio.open(layer) as src:\n",
    "            if src.crs != ref.crs:\n",
    "                print(f\"❌ CRS mismatch: {layer.name} (EPSG:{src.crs.to_epsg()})\")\n",
    "            if src.res != ref.res:\n",
    "                print(f\"❌ Resolution mismatch: {layer.name} ({src.res}m)\")\n",
    "            if src.transform != ref.transform:\n",
    "                print(f\"❌ Transform mismatch: {layer.name}\")\n",
    "    \n",
    "    print(\"✅ Spatial alignment validated (CRS: EPSG:26191, Res: 10m)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_ref =  raw_data_dir / config[\"paths\"][\"ndvi_raw\"]\n",
    "validate_spatial_alignment(ndvi_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Temporal Consistency Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_temporal_bands(years=range(2017, 2024)):\n",
    "    \"\"\"Verify 12 bands (months) exist in annual CHIRPS/ERA5 files.\"\"\"\n",
    "    print(\"\\n=== Temporal Band Check ===\")\n",
    "    for year in years:\n",
    "        chirps_path = weather_processed_dir / f\"CHIRPS_Annual/CHIRPS_{year}_reproj.tif\"\n",
    "        era5_path = weather_processed_dir / f\"ERA5_Annual/ERA5_{year}_reproj.tif\"\n",
    "        \n",
    "        for path in [chirps_path, era5_path]:\n",
    "            if not path.exists():\n",
    "                print(f\"❌ Missing: {path.name}\")\n",
    "                continue\n",
    "            with rasterio.open(path) as src:\n",
    "                if src.count != 12:\n",
    "                    print(f\"❌ {path.name}: {src.count} bands (expected 12)\")\n",
    "\n",
    "    print(\"✅ Temporal bands validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_temporal_bands()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. NoData Consistency Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_ndvi_nodata(ndvi_path):\n",
    "    \"\"\"Set NoData=-9999 for NDVI rasters and replace NaNs.\"\"\"\n",
    "    with rasterio.open(ndvi_path, 'r+') as src:  # Open in read/write mode\n",
    "        # Read data and replace NaNs\n",
    "        data = src.read(1)\n",
    "        data = np.nan_to_num(data, nan=-9999)\n",
    "        \n",
    "        # Update metadata\n",
    "        src.nodata = -9999\n",
    "        \n",
    "        # Write corrected data\n",
    "        src.write(data, 1)\n",
    "    print(f\"Updated {ndvi_path.name}: NoData = -9999\")\n",
    "\n",
    "# Process all NDVI files (2017–2023)\n",
    "for year in range(2017, 2024):\n",
    "    ndvi_path = Path(land_use_processed_dir / f\"Sentinel2_Tadla_NDVI_{year}.tif\")\n",
    "    if ndvi_path.exists():\n",
    "        fix_ndvi_nodata(ndvi_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_nodata():\n",
    "    \"\"\"Ensure NoData = -9999 and valid data ranges.\"\"\"\n",
    "    print(\"\\n=== NoData & Value Ranges ===\")\n",
    "    layers = {\n",
    "        \"Soil_Clay\": (Path(soil_processed_dir / \"tadla_clay_10m.tif\"), (0, 100)),  # %\n",
    "        \"NDVI\": (Path(land_use_processed_dir / \"Sentinel2_Tadla_NDVI_2023.tif\"), (-1, 1)),\n",
    "        \"CHIRPS\": (Path(weather_processed_dir / \"CHIRPS_Annual/CHIRPS_2023_reproj.tif\"), (0, 500)),\n",
    "        \"ERA5\": (Path(weather_processed_dir / \"ERA5_Annual/ERA5_2023_reproj.tif\"), (0, 500)),  # mm/month\n",
    "        \"DEM\": (Path(dem_processed_path), (0, 3500))  # meters\n",
    "    }\n",
    "    \n",
    "    for name, (path, expected_range) in layers.items():\n",
    "        with rasterio.open(path) as src:\n",
    "            data = src.read(1)\n",
    "            valid_data = data[data != src.nodata]\n",
    "            \n",
    "            # Check NoData\n",
    "            if src.nodata != -9999:\n",
    "                print(f\"❌ {name}: NoData = {src.nodata} (expected -9999)\")\n",
    "            \n",
    "            # Check value ranges\n",
    "            min_val, max_val = np.nanmin(valid_data), np.nanmax(valid_data)\n",
    "            if min_val < expected_range[0] or max_val > expected_range[1]:\n",
    "                print(f\"⚠️ {name}: Values ({min_val:.2f}-{max_val:.2f}) outside expected {expected_range}\")\n",
    "\n",
    "    print(\"✅ NoData & ranges validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_nodata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In your validate_nodata() function, update the DEM expected range:\n",
    "layers = {\n",
    "    \"DEM\": (Path(dem_processed_path), (0, 3500))  # New max = 3500m\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(dem_processed_path) as src:\n",
    "    dem = src.read(1)\n",
    "    print(\"Elevation distribution (meters):\")\n",
    "    print(f\"- Min: {dem.min()}\")\n",
    "    print(f\"- 95th percentile: {np.percentile(dem[dem != -9999], 95)}\")\n",
    "    print(f\"- Max: {dem.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Boundary Overlap Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_boundary_overlap():\n",
    "    \"\"\"Ensure all data aligns with Tadla boundary.\"\"\"\n",
    "    print(\"\\n=== Boundary Overlap Check ===\")\n",
    "    tadla = gpd.read_file(tadla_common_path)\n",
    "    \n",
    "    # Sample a central point in Tadla\n",
    "    sample_point = tadla.geometry.centroid[0]\n",
    "    x, y = sample_point.x, sample_point.y\n",
    "    \n",
    "    layers = [\n",
    "        Path(soil_processed_dir / \"tadla_clay_10m.tif\"),\n",
    "        Path(land_use_processed_dir / \"Sentinel2_Tadla_NDVI_2023.tif\")\n",
    "    ]\n",
    "    \n",
    "    for path in layers:\n",
    "        with rasterio.open(path) as src:\n",
    "            bounds = src.bounds\n",
    "            # Check if Tadla centroid is within the bounds of the raster\n",
    "            if not bounds.left <= x <= bounds.right and bounds.bottom <= y <= bounds.top:\n",
    "                print(f\"❌ {path.name}: Does not contain Tadla centroid\")\n",
    "            # Check if >95% of pixels are valid\n",
    "            data = src.read(1)\n",
    "            valid_pct = (data != src.nodata).sum() / data.size * 100\n",
    "            if valid_pct < 95:\n",
    "                print(f\"⚠️ {path.name}: Only {valid_pct:.1f}% valid pixels\")\n",
    "\n",
    "    print(\"✅ Boundary overlap validated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_boundary_overlap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray as rxr\n",
    "\n",
    "# Load the raw ERA5 file for December 2023\n",
    "era5_raw = rxr.open_rasterio(weather_processed_dir / \"ERA5_Annual/ERA5_2023_reproj.tif\").isel(band=11)  # Band 11 = December\n",
    "print(\"ERA5 Raw Values (Dec 2023):\")\n",
    "print(f\"Min: {era5_raw.min().item()}, Max: {era5_raw.max().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray as rxr\n",
    "\n",
    "# Load raw ERA5 data for 2023\n",
    "era5_2023 = rxr.open_rasterio(weather_processed_dir / \"ERA5_Annual/ERA5_2023_reproj.tif\")\n",
    "\n",
    "# Convert units: m/day → mm/day and flip sign\n",
    "era5_2023_mm = era5_2023 * -1000  # Negative → positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ERA5 Corrected Min: {era5_2023_mm.min().item()}, Max: {era5_2023_mm.max().item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "\n",
    "# globally set these defaults\n",
    "dask.config.set({\n",
    "    \"distributed.worker.memory.target\": 0.6,\n",
    "    \"distributed.worker.memory.spill\":  0.7,\n",
    "    \"distributed.worker.memory.pause\":  0.8,\n",
    "})\n",
    "\n",
    "from dask.distributed import Client\n",
    "client = Client(memory_limit=\"15GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# GDAL_CACHEMAX is in megabytes.  2048 MB = 2 GB.\n",
    "os.environ['GDAL_CACHEMAX'] = '2048'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray as rxr\n",
    "import rasterio\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "for year in range(2017, 2024):\n",
    "    input_path = Path(weather_processed_dir / f\"ERA5_Annual/ERA5_{year}_reproj.tif\")\n",
    "    output_path = Path(f\"D:/ERA5/ERA5_{year}_reproj.tif\")\n",
    "    \n",
    "    if not input_path.exists():\n",
    "        print(f\"⚠️ Skipping {input_path.name} (not found)\")\n",
    "        continue\n",
    "    \n",
    "    # Open input file\n",
    "    with rasterio.open(input_path) as src:\n",
    "        # Read metadata and update for 12 bands\n",
    "        meta = src.meta.copy()\n",
    "        meta.update(dtype=\"float32\", count=12)  # <-- Set count=12\n",
    "        \n",
    "        # Create output file with 12 bands\n",
    "        with rasterio.open(output_path, \"w\", **meta) as dst:\n",
    "            for band in range(1, 13):  # Bands 1-12 = January-December\n",
    "                data = src.read(band).astype(np.float32) * -1  # Flip sign\n",
    "                dst.write(data, band)  # Write to the same band in output\n",
    "    \n",
    "    print(f\"✅ Processed {input_path.name} → {output_path.name}\")\n",
    "\n",
    "print(\"All files corrected!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray as rxr\n",
    "\n",
    "# Load corrected ERA5 for 2023\n",
    "era5_corrected = rxr.open_rasterio(weather_processed_dir / f\"ERA5_Annual/ERA5_2017_reproj.tif\")\n",
    "\n",
    "# Check values for December 2023 (band 11)\n",
    "december_2023 = era5_corrected.isel(band=11).isel(x=5000, y=5000).values.item()\n",
    "print(f\"Dec 2023 Evaporation (corrected): {december_2023} mm/month\")\n",
    "\n",
    "# Check global stats\n",
    "print(f\"Min: {era5_corrected.min().item()}, Max: {era5_corrected.max().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
