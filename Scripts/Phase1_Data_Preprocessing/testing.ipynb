{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "import rasterio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from rasterio.mask import mask\n",
    "from rasterio.plot import show\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from osgeo import gdal\n",
    "import ee\n",
    "\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "\n",
    "import rioxarray as rxr\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get project root (adjust based on your folder depth)\n",
    "current_dir = Path(os.getcwd())\n",
    "project_root = current_dir.parent.parent  # Navigate up from \"Scripts/Phase1_Data_Preprocessing\"\n",
    "\n",
    "with open(project_root / \"config.yml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "\n",
    "raw_data_dir = project_root / config[\"paths\"][\"raw_data\"]\n",
    "era5_raw_path = raw_data_dir / config[\"paths\"][\"era5_raw\"]\n",
    "\n",
    "# Processed data paths\n",
    "processed_data_dir = project_root / config[\"paths\"][\"processed_data\"]\n",
    "soil_processed_dir = processed_data_dir / \"GIS/Soil\"\n",
    "output_dir = processed_data_dir / \"GIS/Study_Area_Boundary\"\n",
    "output_path = output_dir / \"Tadla_plain_common.shp\"\n",
    "tadla_common_path = processed_data_dir / config[\"paths\"][\"tadla_boundary_processed\"]\n",
    "soil_processed_path = processed_data_dir / config[\"paths\"][\"soil_processed\"]\n",
    "dem_processed_path = processed_data_dir / config[\"paths\"][\"dem_processed\"]\n",
    "slope_path = processed_data_dir / \"GIS/Topography/tadla_slope.tif\"\n",
    "aspect_path = processed_data_dir / \"GIS/Topography/tadla_aspect.tif\"\n",
    "chirps_processed_path = processed_data_dir / config[\"paths\"][\"chirps_processed\"]\n",
    "era5_processed_path = processed_data_dir / config[\"paths\"][\"era5_processed\"]\n",
    "wv0010_processed_path = processed_data_dir / config[\"paths\"][\"wv0010_processed\"]\n",
    "topography_processed_dir = processed_data_dir / \"GIS/Topography\"\n",
    "\n",
    "land_use_processed_dir = processed_data_dir / config[\"paths\"][\"land_use_processed\"]\n",
    "\n",
    "processed_dir = project_root / Path(config['paths']['processed_data'])\n",
    "soil_dir = processed_dir / \"GIS/Soil\" # Soil data directory: clay, sand, silt, ocd, wv0110\n",
    "dem_path = processed_dir / \"GIS/Topography/tadla_dem_10m.tif\" \n",
    "slope_path = processed_dir / \"GIS/Topography/tadla_slope.tif\"\n",
    "aspect_path = processed_dir / \"GIS/Topography/tadla_aspect.tif\"\n",
    "rainfall_dir = processed_dir / \"Weather/CHIRPS_Annual\" # Rainfall data directory: chirps from 2017 to 2023, 1 file per year with 12 bands\n",
    "evapotranspiration_dir = processed_dir / \"Weather/ERA5_Annual\" # Evapotranspiration data directory: era5 from 2017 to 2023, 1 file per year with 12 bands\n",
    "boundaries_dir = processed_dir / \"GIS/Study_Area_Boundary\" \n",
    "ndvi_dir = processed_dir / \"GIS/Land_Use\" # NDVI data directory: ndvi from 2017 to 2023, 1 file per year with 12 bands\n",
    "weather_processed_dir = processed_data_dir / \"Weather\"\n",
    "chirps_output_dir = Path(config[\"paths\"][\"chirps_dir\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Spatial Alignment Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_spatial_alignment(reference_path):\n",
    "    \"\"\"Check CRS, resolution, and transform across all datasets.\"\"\"\n",
    "    ref = rasterio.open(reference_path)\n",
    "    layers = [\n",
    "        Path(soil_processed_dir / \"tadla_clay_10m.tif\"),\n",
    "        Path(dem_processed_path),\n",
    "        Path(land_use_processed_dir / \"Sentinel2_Tadla_NDVI_2023.tif\"),\n",
    "        Path(weather_processed_dir / \"CHIRPS_Annual/CHIRPS_2023_reproj.tif\"),\n",
    "        Path(weather_processed_dir / \"ERA5_Annual/ERA5_2023_reproj.tif\")\n",
    "    ]\n",
    "    \n",
    "    print(\"=== Spatial Alignment Check ===\")\n",
    "    for layer in layers:\n",
    "        with rasterio.open(layer) as src:\n",
    "            if src.crs != ref.crs:\n",
    "                print(f\"❌ CRS mismatch: {layer.name} (EPSG:{src.crs.to_epsg()})\")\n",
    "            if src.res != ref.res:\n",
    "                print(f\"❌ Resolution mismatch: {layer.name} ({src.res}m)\")\n",
    "            if src.transform != ref.transform:\n",
    "                print(f\"❌ Transform mismatch: {layer.name}\")\n",
    "    \n",
    "    print(\"✅ Spatial alignment validated (CRS: EPSG:26191, Res: 10m)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_ref =  raw_data_dir / config[\"paths\"][\"ndvi_raw\"]\n",
    "validate_spatial_alignment(ndvi_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Temporal Consistency Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_temporal_bands(years=range(2017, 2024)):\n",
    "    \"\"\"Verify 12 bands (months) exist in annual CHIRPS/ERA5 files.\"\"\"\n",
    "    print(\"\\n=== Temporal Band Check ===\")\n",
    "    for year in years:\n",
    "        chirps_path = weather_processed_dir / f\"CHIRPS_Annual/CHIRPS_{year}_reproj.tif\"\n",
    "        era5_path = weather_processed_dir / f\"ERA5_Annual/ERA5_{year}_reproj.tif\"\n",
    "        \n",
    "        for path in [chirps_path, era5_path]:\n",
    "            if not path.exists():\n",
    "                print(f\"❌ Missing: {path.name}\")\n",
    "                continue\n",
    "            with rasterio.open(path) as src:\n",
    "                if src.count != 12:\n",
    "                    print(f\"❌ {path.name}: {src.count} bands (expected 12)\")\n",
    "\n",
    "    print(\"✅ Temporal bands validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_temporal_bands()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. NoData Consistency Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_ndvi_nodata(ndvi_path):\n",
    "    \"\"\"Set NoData=-9999 for NDVI rasters and replace NaNs.\"\"\"\n",
    "    with rasterio.open(ndvi_path, 'r+') as src:  # Open in read/write mode\n",
    "        # Read data and replace NaNs\n",
    "        data = src.read(1)\n",
    "        data = np.nan_to_num(data, nan=-9999)\n",
    "        \n",
    "        # Update metadata\n",
    "        src.nodata = -9999\n",
    "        \n",
    "        # Write corrected data\n",
    "        src.write(data, 1)\n",
    "    print(f\"Updated {ndvi_path.name}: NoData = -9999\")\n",
    "\n",
    "# Process all NDVI files (2017–2023)\n",
    "for year in range(2017, 2024):\n",
    "    ndvi_path = Path(land_use_processed_dir / f\"Sentinel2_Tadla_NDVI_{year}.tif\")\n",
    "    if ndvi_path.exists():\n",
    "        fix_ndvi_nodata(ndvi_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_nodata():\n",
    "    \"\"\"Ensure NoData = -9999 and valid data ranges.\"\"\"\n",
    "    print(\"\\n=== NoData & Value Ranges ===\")\n",
    "    layers = {\n",
    "        \"Soil_Clay\": (Path(soil_processed_dir / \"tadla_clay_10m.tif\"), (0, 100)),  # %\n",
    "        \"NDVI\": (Path(land_use_processed_dir / \"Sentinel2_Tadla_NDVI_2023.tif\"), (-1, 1)),\n",
    "        \"CHIRPS\": (Path(weather_processed_dir / \"CHIRPS_Annual/CHIRPS_2023_reproj.tif\"), (0, 500)),\n",
    "        \"ERA5\": (Path(weather_processed_dir / \"ERA5_Annual/ERA5_2023_reproj.tif\"), (0, 20)),  # mm/month\n",
    "        \"DEM\": (Path(dem_processed_path), (0, 3500))  # meters\n",
    "    }\n",
    "    \n",
    "    for name, (path, expected_range) in layers.items():\n",
    "        with rasterio.open(path) as src:\n",
    "            data = src.read(1)\n",
    "            valid_data = data[data != src.nodata]\n",
    "            \n",
    "            # Check NoData\n",
    "            if src.nodata != -9999:\n",
    "                print(f\"❌ {name}: NoData = {src.nodata} (expected -9999)\")\n",
    "            \n",
    "            # Check value ranges\n",
    "            min_val, max_val = np.nanmin(valid_data), np.nanmax(valid_data)\n",
    "            if min_val < expected_range[0] or max_val > expected_range[1]:\n",
    "                print(f\"⚠️ {name}: Values ({min_val:.2f}-{max_val:.2f}) outside expected {expected_range}\")\n",
    "\n",
    "    print(\"✅ NoData & ranges validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_nodata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In your validate_nodata() function, update the DEM expected range:\n",
    "layers = {\n",
    "    \"DEM\": (Path(dem_processed_path), (0, 3500))  # New max = 3500m\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(dem_processed_path) as src:\n",
    "    dem = src.read(1)\n",
    "    print(\"Elevation distribution (meters):\")\n",
    "    print(f\"- Min: {dem.min()}\")\n",
    "    print(f\"- 95th percentile: {np.percentile(dem[dem != -9999], 95)}\")\n",
    "    print(f\"- Max: {dem.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Boundary Overlap Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_boundary_overlap():\n",
    "    \"\"\"Ensure all data aligns with Tadla boundary.\"\"\"\n",
    "    print(\"\\n=== Boundary Overlap Check ===\")\n",
    "    tadla = gpd.read_file(tadla_common_path)\n",
    "    \n",
    "    # Sample a central point in Tadla\n",
    "    sample_point = tadla.geometry.centroid[0]\n",
    "    x, y = sample_point.x, sample_point.y\n",
    "    \n",
    "    layers = [\n",
    "        Path(soil_processed_dir / \"tadla_clay_10m.tif\"),\n",
    "        Path(land_use_processed_dir / \"Sentinel2_Tadla_NDVI_2023.tif\")\n",
    "    ]\n",
    "    \n",
    "    for path in layers:\n",
    "        with rasterio.open(path) as src:\n",
    "            bounds = src.bounds\n",
    "            # Check if Tadla centroid is within the bounds of the raster\n",
    "            if not bounds.left <= x <= bounds.right and bounds.bottom <= y <= bounds.top:\n",
    "                print(f\"❌ {path.name}: Does not contain Tadla centroid\")\n",
    "            # Check if >95% of pixels are valid\n",
    "            data = src.read(1)\n",
    "            valid_pct = (data != src.nodata).sum() / data.size * 100\n",
    "            if valid_pct < 95:\n",
    "                print(f\"⚠️ {path.name}: Only {valid_pct:.1f}% valid pixels\")\n",
    "\n",
    "    print(\"✅ Boundary overlap validated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_boundary_overlap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Verify ERA5 Data Integrity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check Raw ERA5 Values (Before Processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray as rxr\n",
    "from rasterio.plot import show\n",
    "\n",
    "# Load raw ERA5 data for December 2023\n",
    "era5_raw = rxr.open_rasterio(\"D:/ERA5/ERA5_2017_reproj.tif\").isel(band=11)\n",
    "\n",
    "print(\"=== ERA5 Metadata ===\")\n",
    "print(f\"CRS: {era5_raw.rio.crs}\")  # Should be EPSG:26191\n",
    "print(f\"NoData: {era5_raw.rio.nodata}\")  # Should be -9999\n",
    "print(f\"Shape: {era5_raw.rio.shape}\")  # Expected: (height, width) matching your study area\n",
    "print(f\"Min: {era5_raw.min().item()}, Max: {era5_raw.max().item()}\")  # Expected: ~0–300 mm/month\n",
    "\n",
    "\n",
    "# Check time metadata (if available)\n",
    "if \"time\" in era5_raw.coords:\n",
    "    print(\"Time coordinates:\")\n",
    "    print(era5_raw.time.values)  # Should show monthly/daily timestamps\n",
    "else:\n",
    "    print(\"No time coordinate found. Bands may represent arbitrary time steps.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Reprocess ERA5 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Convert Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the corrected ERA5 raster\n",
    "era5 = rxr.open_rasterio(\"D:/ERA5/ERA5_2017_reproj.tif\")\n",
    "\n",
    "# Print global metadata\n",
    "print(\"=== Global Metadata ===\")\n",
    "print(f\"CRS:             {era5.rio.crs}\")\n",
    "print(f\"Resolution:      {era5.rio.resolution()}\")\n",
    "print(f\"NoData value:    {era5.rio.nodata}\")\n",
    "print(f\"Shape (b, h, w): {era5.shape}\")\n",
    "print(f\"Band count:      {era5.rio.count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(era5.min().item(), era5.max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray as rxr\n",
    "\n",
    "# Open with Dask chunking (one band at a time, and 1024×1024 pixel tiles)\n",
    "era5 = rxr.open_rasterio(\n",
    "    weather_processed_dir / \"ERA5_Annual/ERA5_2017_reproj.tif\",\n",
    "    masked=True,\n",
    "    chunks={'band': 1, 'x': 1024, 'y': 1024}\n",
    ")\n",
    "\n",
    "# Lazy flip of sign\n",
    "era5_corrected = era5 * -1\n",
    "\n",
    "# Write nodata into the dataset\n",
    "era5_corrected.rio.write_nodata(-9999, inplace=True)\n",
    "\n",
    "# Export using windowed writes (never loads full array into memory)\n",
    "era5_corrected.rio.to_raster(\n",
    "    \"D:/ERA5/ERA5_2017_reproj.tif\",\n",
    "    driver=\"GTiff\",\n",
    "    tiled=True,\n",
    "    compress=\"DEFLATE\",\n",
    "    windowed=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Convert Units and Flip Signs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Boundary Overlap Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from rasterio.mask import geometry_mask\n",
    "\n",
    "# Load Tadla boundary\n",
    "tadla = gpd.read_file(tadla_common_path).to_crs(era5_raw.rio.crs)\n",
    "\n",
    "# Create mask of Tadla geometry\n",
    "mask = geometry_mask(\n",
    "    geometries=tadla.geometry,\n",
    "    transform=era5_raw.rio.transform(),\n",
    "    invert=True,\n",
    "    out_shape=era5_raw.rio.shape\n",
    ")\n",
    "\n",
    "# Check overlap\n",
    "if not np.any(mask):\n",
    "    print(\"❌ ERA5 data does NOT overlap with Tadla boundary!\")\n",
    "else:\n",
    "    print(\"✅ ERA5 overlaps with Tadla boundary\")\n",
    "\n",
    "# Plot the mask\n",
    "plt.imshow(mask, cmap=\"gray\")\n",
    "plt.title(\"Tadla Boundary Mask on ERA5 Grid\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "\n",
    "# globally set these defaults\n",
    "dask.config.set({\n",
    "    \"distributed.worker.memory.target\": 0.6,\n",
    "    \"distributed.worker.memory.spill\":  0.7,\n",
    "    \"distributed.worker.memory.pause\":  0.8,\n",
    "})\n",
    "\n",
    "from dask.distributed import Client\n",
    "client = Client(memory_limit=\"15GB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
