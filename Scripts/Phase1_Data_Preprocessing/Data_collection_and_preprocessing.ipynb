{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Defining the Study Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "import rasterio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from rasterio.mask import mask\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from osgeo import gdal\n",
    "import ee\n",
    "\n",
    "import xarray as xr\n",
    "import rioxarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Load config.yml\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Get project root (adjust based on your folder depth)\n",
    "current_dir = Path(os.getcwd())\n",
    "project_root = current_dir.parent.parent  # Navigate up from \"Scripts/Phase1_Data_Preprocessing\"\n",
    "\n",
    "with open(project_root / \"config.yml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Print the config dictionary to debug\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Construct paths\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Raw data paths\n",
    "raw_data_dir = project_root / config[\"paths\"][\"raw_data\"]\n",
    "soil_raw_dir = raw_data_dir / \"GIS/Soil\"  # Matches your hardcoded path structure\n",
    "morocco_path = raw_data_dir / config[\"paths\"][\"morocco_path\"]\n",
    "tadla_plain_path = raw_data_dir / config[\"paths\"][\"tadla_plain_raw\"]\n",
    "tadla_plain_boundary_path = raw_data_dir / config[\"paths\"][\"tadla_plain_boundary_raw\"]\n",
    "soil_raw_path = raw_data_dir / config[\"paths\"][\"soil_raw\"]\n",
    "dem_raw_path = raw_data_dir / config[\"paths\"][\"dem_raw\"]\n",
    "chirps_raw_path = raw_data_dir / config[\"paths\"][\"chirps_raw\"]\n",
    "era5_raw_path = raw_data_dir / config[\"paths\"][\"era5_raw\"]\n",
    "wv0010_raw_path = raw_data_dir / config[\"paths\"][\"wv0010_raw\"]\n",
    "ndvi_path = raw_data_dir / config[\"paths\"][\"ndvi_raw\"]\n",
    "\n",
    "\n",
    "# Processed data paths\n",
    "processed_data_dir = project_root / config[\"paths\"][\"processed_data\"]\n",
    "soil_processed_dir = processed_data_dir / \"GIS/Soil\"\n",
    "output_dir = processed_data_dir / \"GIS/Study_Area_Boundary\"\n",
    "output_path = output_dir / \"Tadla_plain_common.shp\"\n",
    "tadla_common_path = processed_data_dir / config[\"paths\"][\"tadla_boundary_processed\"]\n",
    "soil_processed_path = processed_data_dir / config[\"paths\"][\"soil_processed\"]\n",
    "dem_processed_path = processed_data_dir / config[\"paths\"][\"dem_processed\"]\n",
    "slope_path = processed_data_dir / \"GIS/Topography/tadla_slope.tif\"\n",
    "aspect_path = processed_data_dir / \"GIS/Topography/tadla_aspect.tif\"\n",
    "chirps_processed_path = processed_data_dir / config[\"paths\"][\"chirps_processed\"]\n",
    "era5_processed_path = processed_data_dir / config[\"paths\"][\"era5_processed\"]\n",
    "wv0010_processed_path = processed_data_dir / config[\"paths\"][\"wv0010_processed\"]\n",
    "\n",
    "\n",
    "# Harmonized data paths\n",
    "harmonized_dir = Path(config[\"paths\"][\"harmonized_data\"])\n",
    "weather_processed_dir = processed_data_dir / \"Weather\"\n",
    "chirps_output_dir = Path(config[\"paths\"][\"chirps_dir\"])\n",
    "\n",
    "output_path_dataset = harmonized_dir / \"tadla_spatiotemporal_dataset.nc\"\n",
    "\n",
    "\n",
    "\n",
    "# Ensure output directories exist\n",
    "harmonized_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(era5_processed_path.parent, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Morocco boundary\n",
    "morocco = gpd.read_file(morocco_path)\n",
    "\n",
    "# Check the first few rows to see province names\n",
    "morocco.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(morocco.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morocco_merchiche = morocco.to_crs(epsg=26191)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morocco_merchiche.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tadla Plain shapefile\n",
    "tadla_plain_polygon = gpd.read_file(tadla_plain_path)\n",
    "\n",
    "# Check the data\n",
    "print(tadla_plain_polygon)  # Show first few rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tadla_plain_polygon.plot()  # Plot the geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Study area size: {tadla_plain_polygon.geometry.area} m²\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproject to Merchich (EPSG:26191)\n",
    "tadla_merchiche = tadla_plain_polygon.to_crs(epsg=26191)\n",
    "\n",
    "# Calculate area\n",
    "area_m2 = tadla_merchiche.geometry.area\n",
    "print(f\"Study area size: {area_m2[0]:.2f} m²\")  \n",
    "# Example output: \"Study area size: 1300000000.00 m²\"\n",
    "\n",
    "area_ha = area_m2 / 10000\n",
    "print(f\"Study area size: {area_ha[0]:.2f} hectares\")  \n",
    "# Example output: \"Study area size: 130000.00 hectares\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tadla_merchiche.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned boundary shapefile\n",
    "Tadla_plain_boundary = gpd.read_file(tadla_plain_boundary_path)\n",
    "# Check the current CRS\n",
    "print(Tadla_plain_boundary.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Merchich CRS if needed\n",
    "if Tadla_plain_boundary.crs != \"EPSG:26191\":\n",
    "    Tadla_plain_boundary = Tadla_plain_boundary.to_crs(epsg=26191)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tadla_plain_boundary.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume these are already loaded and in the same CRS (EPSG:26191)\n",
    "# tadla_merchiche: full administrative boundary (Merchich)\n",
    "# tadla_plain_polygone: digitized Tadla plain (which may be slightly off)\n",
    "\n",
    "# Compute the common (intersecting) area between the two layers\n",
    "tadla_plain = gpd.overlay(Tadla_plain_boundary, tadla_merchiche, how='intersection')\n",
    "\n",
    "# Save the resulting common area shapefile for further analysis\n",
    "tadla_plain.to_file(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Plot layers with explicit labels\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "tadla_merchiche.plot(ax=ax, facecolor=\"none\", edgecolor=\"red\", linewidth=2)\n",
    "Tadla_plain_boundary.plot(ax=ax, facecolor=\"blue\", alpha=0.5, edgecolor=\"blue\")\n",
    "tadla_plain.plot(ax=ax, facecolor=\"green\", alpha=0.5, edgecolor=\"black\")\n",
    "\n",
    "# Create custom legend\n",
    "legend_labels = {\n",
    "    \"Full Admin Boundary\": \"red\",\n",
    "    \"Digitized Tadla Plain\": \"blue\",\n",
    "    \"Common Area\": \"green\"\n",
    "}\n",
    "patches = [Patch(color=color, label=label) for label, color in legend_labels.items()]\n",
    "plt.legend(handles=patches)\n",
    "\n",
    "plt.title(\"Common Area between Tadla Plain and Full Admin Boundary\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot layers with explicit labels\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "tadla_merchiche.plot(ax=ax, facecolor=\"none\", edgecolor=\"red\", linewidth=2)\n",
    "Tadla_plain_boundary.plot(ax=ax, facecolor=\"blue\", alpha=0.5, edgecolor=\"blue\")\n",
    "tadla_plain.plot(ax=ax, facecolor=\"green\", alpha=0.5, edgecolor=\"black\")\n",
    "morocco_merchiche.plot(ax=ax, facecolor=\"none\", edgecolor=\"brown\", linewidth=1)\n",
    "\n",
    "# Create custom legend\n",
    "legend_labels = {\n",
    "    \"Full Admin Boundary\": \"red\",\n",
    "    \"Digitized Tadla Plain\": \"blue\",\n",
    "    \"Common Area\": \"green\",\n",
    "    \"Morocco\": \"brown\"\n",
    "}\n",
    "patches = [Patch(color=color, label=label) for label, color in legend_labels.items()]\n",
    "plt.legend(handles=patches)\n",
    "\n",
    "plt.title(\"Common Area between Tadla Plain and Full Admin Boundary of Morocco\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tadla_plain = tadla_plain.to_crs(epsg=26191)  # Ensure projection\n",
    "tadla_merchiche = tadla_merchiche.to_crs(epsg=26191)\n",
    "\n",
    "area_plain_m2 = tadla_plain.geometry.area.sum()\n",
    "area_full_m2 = tadla_merchiche.geometry.area.sum()\n",
    "\n",
    "print(f\"Tadla Plain area: {area_plain_m2:.2f} m²\")\n",
    "print(f\"Full Admin Boundary area: {area_full_m2:.2f} m²\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def reproject_raster(input_path, output_path, target_crs):\n",
    "    with rasterio.open(input_path) as src:\n",
    "        transform, width, height = calculate_default_transform(\n",
    "            src.crs, target_crs, src.width, src.height, *src.bounds\n",
    "        )\n",
    "        metadata = src.meta.copy()\n",
    "        metadata.update({\n",
    "            \"crs\": target_crs,\n",
    "            \"transform\": transform,\n",
    "            \"width\": width,\n",
    "            \"height\": height\n",
    "        })\n",
    "\n",
    "        with rasterio.open(output_path, \"w\", **metadata) as dest:\n",
    "            reproject(\n",
    "                source=rasterio.band(src, 1),\n",
    "                destination=rasterio.band(dest, 1),\n",
    "                src_transform=src.transform,\n",
    "                src_crs=src.crs,\n",
    "                dst_transform=transform,\n",
    "                dst_crs=target_crs\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Downloading Soil Data (SoilGrids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load Tadla boundary (EPSG:26191)\n",
    "tadla = gpd.read_file(tadla_common_path)\n",
    "tadla = tadla.to_crs(\"EPSG:26191\")\n",
    "\n",
    "# Get bounding box in Merchich coordinates\n",
    "minx, miny, maxx, maxy = tadla.total_bounds\n",
    "print(f\"X: {minx}, {maxx}\")  # Easting bounds\n",
    "print(f\"Y: {miny}, {maxy}\")  # Northing bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Defining Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bounding box of Tadla Plain in EPSG:26191 (from your URL)\n",
    "minx, maxx = 339200, 459750  # X (Easting)\n",
    "miny, maxy = 164400, 241200  # Y (Northing)\n",
    "\n",
    "# Soil layers and their COVERAGEIDs (adjust if needed)\n",
    "layers = {\n",
    "    \"clay\": \"clay_0-5cm_mean\",\n",
    "    \"silt\": \"silt_0-5cm_mean\",\n",
    "    \"sand\": \"sand_0-5cm_mean\",\n",
    "    \"ocd\": \"ocd_0-5cm_mean\",    # Organic carbon density\n",
    "    \"wv0010\": \"wv0010_0-5cm_mean\"     # Water content at saturation\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Python Script to Download All Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.makedirs(soil_raw_dir, exist_ok=True)\n",
    "\n",
    "for param, coverage_id in layers.items():\n",
    "    url = (\n",
    "        f\"https://maps.isric.org/mapserv?map=/map/{param}.map&\"\n",
    "        f\"SERVICE=WCS&\"\n",
    "        f\"VERSION=2.0.1&\"\n",
    "        f\"REQUEST=GetCoverage&\"\n",
    "        f\"COVERAGEID={coverage_id}&\"\n",
    "        f\"FORMAT=GEOTIFF_INT16&\"  # Or GEOTIFF_FLOAT32 for raw values\n",
    "        f\"SUBSET=X({minx},{maxx})&\"\n",
    "        f\"SUBSET=Y({miny},{maxy})&\"\n",
    "        f\"SUBSETTINGCRS=http://www.opengis.net/def/crs/EPSG/0/26191&\"\n",
    "        f\"OUTPUTCRS=http://www.opengis.net/def/crs/EPSG/0/26191\"\n",
    "    )\n",
    "    print(url)\n",
    "    \n",
    "    # Download and save\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        output_path = os.path.join(soil_raw_dir, f\"tadla_{param}.tif\")\n",
    "        with open(output_path, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Downloaded {param} to {output_path}\")\n",
    "    else:\n",
    "        print(f\"Failed to download {param}: HTTP {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Post-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Unit Conversion:\n",
    "\n",
    "    SoilGrids stores integer values as actual value × 10. \n",
    "    \n",
    "    For example:\n",
    "        A pixel value of 150 = 15% clay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process soil data\n",
    "\n",
    "    # = src.profile\n",
    "   \n",
    "\n",
    "with rasterio.open(soil_raw_path) as src:\n",
    "    clay = src.read(1)\n",
    "    clay = clay.astype(np.float32) / 10  # Convert to %\n",
    "    profile = src.profile.copy()\n",
    "    profile.update(dtype=rasterio.float32)\n",
    "\n",
    "    with rasterio.open(soil_processed_path, \"w\", **profile) as dst:\n",
    "        dst.write(src.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open raw water content data\n",
    "with rasterio.open(wv0010_raw_path) as src:\n",
    "    data = src.read(1) / 10  # Convert to %\n",
    "    profile = src.profile.copy()\n",
    "\n",
    "    # Calculate new dimensions for 10m resolution\n",
    "    new_width = int(src.width * (src.res[0] / 10))  # From ~326m → 10m\n",
    "    new_height = int(src.height * (abs(src.res[1]) / 10))  # From ~533m → 10m\n",
    "\n",
    "    # Create empty array for resampled data\n",
    "    resampled_data = np.empty((new_height, new_width), dtype=np.float32)\n",
    "\n",
    "    # Define target transform for 10m resolution\n",
    "    target_transform = rasterio.Affine(10, 0, src.bounds.left, 0, -10, src.bounds.top)\n",
    "\n",
    "    # Resample using bilinear interpolation\n",
    "    reproject(\n",
    "        source=data,\n",
    "        destination=resampled_data,\n",
    "        src_transform=src.transform,\n",
    "        dst_transform=target_transform,\n",
    "        src_crs=src.crs,\n",
    "        dst_crs=src.crs,\n",
    "        resampling=Resampling.bilinear\n",
    "    )\n",
    "\n",
    "# Update metadata for the processed file\n",
    "profile.update({\n",
    "    \"transform\": target_transform,\n",
    "    \"width\": new_width,\n",
    "    \"height\": new_height,\n",
    "    \"dtype\": \"float32\"\n",
    "})\n",
    "\n",
    "# Save resampled data\n",
    "with rasterio.open(wv0010_processed_path, \"w\", **profile) as dst:\n",
    "    dst.write(resampled_data, 1)\n",
    "\n",
    "print(f\"Resampled water content saved to: {wv0010_processed_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(wv0010_processed_path) as src:\n",
    "    print(src.res)  # Should output (10.0, 10.0)\n",
    "    print(src.read(1).min(), src.read(1).max())  # e.g., 0.0–38.9%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Validate CRS Alignment\n",
    "\n",
    "    Confirm all downloaded rasters are in EPSG:26191"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with rasterio.open(soil_raw_path) as src:\n",
    "    print(src.crs)  # Should print \"EPSG:26191\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: DEM Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download DEM Data\n",
    "\n",
    "    We’ll use ALOS PALSAR Global DEM (12.5m resolution) from Google Earth Engine (GEE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load Tadla boundary (ensure this path is correct)\n",
    "tadla_shp_path = tadla_common_path\n",
    "tadla = gpd.read_file(tadla_shp_path)\n",
    "\n",
    "# Check current CRS\n",
    "print(f\"Current CRS: {tadla.crs}\")  # Should be EPSG:26191 (Merchich)\n",
    "\n",
    "# Reproject to WGS84 (EPSG:4326)\n",
    "tadla_wgs84 = tadla.to_crs(\"EPSG:4326\")\n",
    "\n",
    "# Save reprojected shapefile\n",
    "tadla_wgs84.to_file(tadla_shp_path)  # Overwrite or save to a new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "project_id = os.environ.get('GCP_PROJECT')\n",
    "if not project_id:\n",
    "    raise ValueError(\"The environment variable GCP_PROJECT is not set.\")\n",
    "\n",
    "print(\"Using project ID:\", project_id)\n",
    "\n",
    "import ee\n",
    "ee.Authenticate()\n",
    "ee.Initialize(project=project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test authentication\n",
    "print(ee.Image(\"NASA/NASADEM_HGT/001\").get(\"title\").getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = ee.Geometry.Rectangle(\n",
    "    [-7.5, 32.0, -5.5, 32.8],  # minx, miny, maxx, maxy\n",
    "    proj=\"EPSG:4326\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ALOS DEM ImageCollection and select the 'DSM' band\n",
    "dem_collection = ee.ImageCollection(\"JAXA/ALOS/AW3D30/V3_2\").select('DSM')\n",
    "\n",
    "# Mosaic the collection into a single image (combines all tiles over Tadla)\n",
    "dem = dem_collection.mosaic().clip(bbox)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to Google Drive\n",
    "task = ee.batch.Export.image.toDrive(\n",
    "    image=dem,\n",
    "    description='Tadla_DEM',\n",
    "    folder='Tadla_Project',\n",
    "    scale=12.5,\n",
    "    region=bbox,\n",
    "    crs=\"EPSG:26191\",  # Merchich CRS\n",
    "    fileFormat='GeoTIFF',\n",
    "    maxPixels=1e13\n",
    ")\n",
    "task.start()\n",
    "\n",
    "# Monitor task progress\n",
    "print(f\"Task ID: {task.id}\")\n",
    "print(\"Check progress at: https://code.earthengine.google.com/tasks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Preprocess DEM\n",
    "    \n",
    "    Once downloaded, move the DEM to Data/Raw/GIS/Topography/ and preprocess it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load boundary and ensure it's in the same CRS as the DEM (EPSG:26191)\n",
    "tadla = gpd.read_file(tadla_common_path)\n",
    "if tadla.crs != \"EPSG:26191\":\n",
    "    tadla = tadla.to_crs(\"EPSG:26191\")\n",
    "\n",
    "# Load DEM and check its CRS\n",
    "with rasterio.open(dem_raw_path) as src:\n",
    "    dem_crs = src.crs\n",
    "    print(f\"DEM CRS: {dem_crs}\")  # Should be EPSG:26191\n",
    "\n",
    "    # Fix 2: Reproject boundary if DEM is in a different CRS\n",
    "    if tadla.crs != dem_crs:\n",
    "        tadla = tadla.to_crs(dem_crs)\n",
    "\n",
    "    # Fix 3: Validate overlap\n",
    "    dem_bounds = src.bounds\n",
    "    tadla_bounds = tadla.total_bounds\n",
    "    print(f\"DEM Bounds: {dem_bounds}\")\n",
    "    print(f\"Tadla Bounds: {tadla_bounds}\")\n",
    "\n",
    "    if not (\n",
    "        (tadla_bounds[0] > dem_bounds.left) &\n",
    "        (tadla_bounds[2] < dem_bounds.right) &\n",
    "        (tadla_bounds[1] > dem_bounds.bottom) &\n",
    "        (tadla_bounds[3] < dem_bounds.top)\n",
    "    ):\n",
    "        raise ValueError(\"DEM and boundary do not overlap. Check their geographic extents!\")\n",
    "\n",
    "    # Clip DEM\n",
    "    tadla_dem, transform = mask(src, tadla.geometry, crop=True)\n",
    "    meta = src.meta.copy()\n",
    "    meta.update({\n",
    "        \"height\": tadla_dem.shape[1],\n",
    "        \"width\": tadla_dem.shape[2],\n",
    "        \"transform\": transform,\n",
    "        \"crs\": dem_crs\n",
    "    })\n",
    "\n",
    "# Save clipped DEM\n",
    "with rasterio.open(dem_processed_path, \"w\", **meta) as dest:\n",
    "    dest.write(tadla_dem)\n",
    "print(f\"Clipped DEM saved to: {dem_processed_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"DEM exists: {dem_raw_path.exists()}\")\n",
    "print(f\"Boundary exists: {tadla_common_path.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Derive Slope and Aspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Calculating Slope and Aspect Using GDAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable GDAL exceptions\n",
    "gdal.UseExceptions()\n",
    "\n",
    "# Ensure output directories exist\n",
    "os.makedirs(slope_path.parent, exist_ok=True)\n",
    "\n",
    "# Calculate slope\n",
    "slope = gdal.DEMProcessing(\n",
    "    destName=str(slope_path),\n",
    "    srcDS=str(dem_processed_path),\n",
    "    processing=\"slope\",\n",
    "    format=\"GTiff\",\n",
    "    slopeFormat=\"degree\"\n",
    ")\n",
    "\n",
    "# Calculate aspect\n",
    "aspect = gdal.DEMProcessing(\n",
    "    destName=str(aspect_path),\n",
    "    srcDS=str(dem_processed_path),\n",
    "    processing=\"aspect\",\n",
    "    format=\"GTiff\"\n",
    ")\n",
    "\n",
    "print(f\"Slope saved to: {slope_path}\")\n",
    "print(f\"Aspect saved to: {aspect_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Weather Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download CHIRPS Rainfall Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate and initialize GEE\n",
    "ee.Authenticate()\n",
    "ee.Initialize(project=project_id)\n",
    "\n",
    "# Load CHIRPS data\n",
    "chirps = ee.ImageCollection(\"UCSB-CHG/CHIRPS/DAILY\")\n",
    "\n",
    "# Define Tadla Plain geometry (use your boundary)\n",
    "tadla = ee.Geometry.Rectangle([-7.5, 32.0, -5.5, 32.8])\n",
    "\n",
    "# Filter and export\n",
    "chirps_tadla = chirps.filterBounds(tadla).filterDate('2010-01-01', '2023-12-31')\n",
    "task = ee.batch.Export.image.toDrive(\n",
    "    image=chirps_tadla.mean(),\n",
    "    description='CHIRPS_Tadla',\n",
    "    folder='Tadla_Project',\n",
    "    scale=5000,\n",
    "    region=tadla,\n",
    "    crs=\"EPSG:26191\"\n",
    ")\n",
    "task.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Preprocess CHIRPS Rainfall Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load boundary (EPSG:4326)\n",
    "boundary_path = tadla_common_path\n",
    "tadla = gpd.read_file(boundary_path)\n",
    "\n",
    "# Reproject boundary to EPSG:26191 (Merchich)\n",
    "tadla_merc = tadla.to_crs(\"EPSG:26191\")\n",
    "\n",
    "# Save reprojected boundary\n",
    "tadla_merc.to_file(boundary_path)  # Overwrite or save to a new file\n",
    "\n",
    "# Load Tadla boundary\n",
    "tadla = gpd.read_file(tadla_common_path)\n",
    "print(f\"Boundary CRS: {tadla.crs}\")  # Should be EPSG:26191 (Merchich)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tadla boundary\n",
    "tadla = gpd.read_file(tadla_common_path)\n",
    "\n",
    "# Load CHIRPS data\n",
    "with rasterio.open(chirps_raw_path) as src:\n",
    "    chirps_data, transform = mask(src, tadla.geometry, crop=True)\n",
    "    meta = src.meta.copy()\n",
    "\n",
    "# Update metadata\n",
    "meta.update({\n",
    "    \"height\": chirps_data.shape[1],\n",
    "    \"width\": chirps_data.shape[2],\n",
    "    \"transform\": transform,\n",
    "    \"crs\": \"EPSG:26191\"\n",
    "})\n",
    "\n",
    "# Save clipped rainfall data\n",
    "with rasterio.open(chirps_processed_path, \"w\", **meta) as dest:\n",
    "    dest.write(chirps_data)\n",
    "\n",
    "print(f\"Clipped CHIRPS data saved to: {chirps_processed_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Download ERA5 Temperature/ET Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Authenticate and initialize Earth Engine\n",
    "ee.Authenticate()\n",
    "ee.Initialize(project=project_id)\n",
    "\n",
    "\n",
    "# Define the bounding box for the Tadla Plain (in WGS84)\n",
    "bbox = ee.Geometry.Rectangle(\n",
    "   [-7.5, 32.0, -5.5, 32.8],  # minx, miny, maxx, maxy\n",
    "    proj=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# Load the ERA5 DAILY ImageCollection for a chosen period and filter by location\n",
    "era5_daily = ee.ImageCollection(\"ECMWF/ERA5/DAILY\") \\\n",
    "    .filterDate(\"2010-01-01\", \"2023-12-31\") \\\n",
    "    .filterBounds(bbox)\n",
    "\n",
    "# Get the first image to inspect available bands\n",
    "first_img = ee.Image(era5_daily.first())\n",
    "band_names = first_img.bandNames().getInfo()\n",
    "print(\"Available bands in ERA5 DAILY dataset:\", band_names)\n",
    "\n",
    "# Choose the appropriate band.\n",
    "# For example, if you're aiming for evaporation data, check for \"evaporation\" or \"total_evaporation\"\n",
    "if \"evaporation\" in band_names:\n",
    "    selected_band = \"evaporation\"\n",
    "elif \"total_evaporation\" in band_names:\n",
    "    selected_band = \"total_evaporation\"\n",
    "else:\n",
    "    # If neither exists, default to the first available band (or update with the correct one)\n",
    "    selected_band = band_names[0]\n",
    "\n",
    "print(\"Selected band:\", selected_band)\n",
    "\n",
    "# Mosaic the collection to combine overlapping images and select the chosen band, then clip to your area\n",
    "era5_selected = era5_daily.select(selected_band).mosaic().clip(bbox)\n",
    "\n",
    "# Export the resulting image to your Google Drive\n",
    "task = ee.batch.Export.image.toDrive(\n",
    "    image=era5_selected,\n",
    "    description='ERA5_Evaporation_Export',\n",
    "    folder='ERA5_Exports',  # Your Google Drive folder name\n",
    "    scale=1000,             # Adjust scale (resolution) as needed\n",
    "    region=bbox,\n",
    "    crs=\"EPSG:26191\",        # Exporting in WGS84; change if needed\n",
    "    fileFormat='GeoTIFF',\n",
    "    maxPixels=1e13\n",
    ")\n",
    "task.start()\n",
    "\n",
    "print(\"Export task started with ID:\", task.id)\n",
    "print(\"Monitor the task at: https://code.earthengine.google.com/tasks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tadla boundary\n",
    "tadla = gpd.read_file(tadla_common_path)\n",
    "# Clip ERA5 data to Tadla boundary\n",
    "with rasterio.open(era5_raw_path) as src:\n",
    "    era5_data, transform = mask(src, tadla.geometry, crop=True)\n",
    "    meta = src.meta.copy()\n",
    "    meta.update({\n",
    "        \"height\": era5_data.shape[1],\n",
    "        \"width\": era5_data.shape[2],\n",
    "        \"transform\": transform,\n",
    "        \"crs\": src.crs  # Ensure this matches the boundary CRS (EPSG:26191)\n",
    "    })\n",
    "\n",
    "# Save clipped ERA5 data\n",
    "with rasterio.open(era5_processed_path, \"w\", **meta) as dest:\n",
    "    dest.write(era5_data)\n",
    "\n",
    "print(f\"Clipped ERA5 data saved to: {era5_processed_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Land Use/Crop Maps (Sentinel-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Authenticate & Initialize Earth Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate (this will open a browser window for authentication if needed)\n",
    "ee.Authenticate()\n",
    "\n",
    "# Initialize with your project settings (make sure you have set your GCP_PROJECT in your environment variables)\n",
    "ee.Initialize(project=project_id)\n",
    "\n",
    "print(\"Earth Engine has been initialized successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tadla = gpd.read_file(tadla_common_path)\n",
    "\n",
    "# Reproject to WGS84 (EPSG:4326) if needed\n",
    "if tadla.crs != \"EPSG:26191\":\n",
    "    tadla = tadla.to_crs(\"EPSG:26191\")\n",
    "\n",
    "# Convert to GEE geometry\n",
    "tadla_geom = ee.Geometry.Polygon(tadla.geometry[0].exterior.coords[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tadla boundary (WGS84)\n",
    "tadla_geom = ee.Geometry.Polygon(\n",
    "    [[-7.5, 32.0], [-5.5, 32.0], [-5.5, 32.8], [-7.5, 32.8]], \n",
    "    proj=\"EPSG:4326\", \n",
    "    geodesic=False\n",
    ")\n",
    "\n",
    "# Reproject to EPSG:26191 (Merchich)\n",
    "tadla_merc = tadla_geom.transform('EPSG:26191', 1)  # 1-meter error margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annual_composite(year):\n",
    "    start_date = f'{year}-04-01'\n",
    "    end_date = f'{year}-09-30'\n",
    "    \n",
    "    # Load Sentinel-2 collection\n",
    "    s2_collection = ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\") \\\n",
    "        .filterBounds(tadla_merc) \\\n",
    "        .filterDate(start_date, end_date) \\\n",
    "        .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 10))\n",
    "    \n",
    "    # Harmonize bands: Select and rename critical bands (B4=Red, B8=NIR)\n",
    "    s2_harmonized = s2_collection.map(\n",
    "        lambda img: img.select(\n",
    "            ['B4', 'B8', 'SCL'],  # Keep only Red, NIR, and Scene Classification\n",
    "            ['red', 'nir', 'scl']  # Rename to avoid conflicts\n",
    "        ).cast({'red': 'float', 'nir': 'float'})  # Force consistent data types\n",
    "    )\n",
    "    \n",
    "    # Compute median composite\n",
    "    composite = s2_harmonized.median()\n",
    "    \n",
    "    # Calculate NDVI\n",
    "    ndvi = composite.expression(\n",
    "        '(nir - red) / (nir + red)', \n",
    "        {'nir': composite.select('nir'), 'red': composite.select('red')}\n",
    "    ).rename('NDVI')\n",
    "    \n",
    "    return ndvi.reproject(crs='EPSG:26191', scale=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_ndvi(year):\n",
    "    ndvi = get_annual_composite(year)\n",
    "    task = ee.batch.Export.image.toDrive(\n",
    "        image=ndvi,\n",
    "        description=f'Sentinel2_Tadla_NDVI_{year}',\n",
    "        folder='Tadla_Project',\n",
    "        scale=10,\n",
    "        region=tadla_merc,\n",
    "        crs='EPSG:26191',\n",
    "        maxPixels=1e13,\n",
    "        fileFormat='GeoTIFF'\n",
    "    )\n",
    "    task.start()\n",
    "    print(f\"Exported {year}: Task ID {task.id}\")\n",
    "\n",
    "# Run for all years (2017–2023)\n",
    "for year in range(2017, 2024):\n",
    "    export_ndvi(year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 – Data Harmonization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Resample Coarse Data (Soil/DEM) to 10m Resolution\n",
    "\n",
    "    Goal: Resample low-resolution datasets (e.g., SoilGrids at 250m) to match NDVI’s 10m grid.\n",
    "    Why: To align all datasets spatially for ML training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract metadata from NDVI 2017\n",
    "with rasterio.open(ndvi_path) as ndvi_ref:\n",
    "    ndvi_transform = ndvi_ref.transform  # 10m resolution transform\n",
    "    ndvi_crs = ndvi_ref.crs             # CRS (EPSG:26191)\n",
    "    ndvi_width = ndvi_ref.width         # Number of columns\n",
    "    ndvi_height = ndvi_ref.height       # Number of rows\n",
    "\n",
    "print(f\"Reference CRS: {ndvi_crs}\")\n",
    "print(f\"Reference resolution: {ndvi_transform[0]}m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.warp import reproject, Resampling\n",
    "import numpy as np\n",
    "\n",
    "# Paths (update with your actual paths)\n",
    "soil_clay_10m = soil_processed_dir / \"tadla_clay_10m.tif\"\n",
    "\n",
    "# Resample clay to 10m using NDVI’s grid\n",
    "with rasterio.open(soil_processed_path) as src:\n",
    "    # Initialize destination array with NDVI dimensions\n",
    "    dst_data = np.zeros((ndvi_height, ndvi_width), dtype=np.float32)\n",
    "    \n",
    "    reproject(\n",
    "        source=rasterio.band(src, 1),\n",
    "        destination=dst_data,\n",
    "        src_transform=src.transform,\n",
    "        dst_transform=ndvi_transform,\n",
    "        src_crs=src.crs,\n",
    "        dst_crs=ndvi_crs,\n",
    "        resampling=Resampling.bilinear  # Use \"nearest\" for categorical data\n",
    "    )\n",
    "    \n",
    "    # Save resampled clay\n",
    "    with rasterio.open(\n",
    "        soil_clay_10m,\n",
    "        \"w\",\n",
    "        driver=\"GTiff\",\n",
    "        height=ndvi_height,\n",
    "        width=ndvi_width,\n",
    "        count=1,\n",
    "        dtype=np.float32,\n",
    "        crs=ndvi_crs,\n",
    "        transform=ndvi_transform,\n",
    "        nodata=src.nodata\n",
    "    ) as dst:\n",
    "        dst.write(dst_data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(soil_clay_10m) as clay_resampled:\n",
    "    print(f\"Resampled clay resolution: {clay_resampled.res}\")  # Should be (10.0, 10.0)\n",
    "    print(f\"CRS: {clay_resampled.crs}\")  # Should match NDVI (EPSG:26191)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_soil_layer(raw_path, processed_path, ndvi_transform, ndvi_crs, ndvi_height, ndvi_width):\n",
    "    with rasterio.open(raw_path) as src:\n",
    "        dst_data = np.zeros((ndvi_height, ndvi_width), dtype=np.float32)\n",
    "        reproject(\n",
    "            source=rasterio.band(src, 1),\n",
    "            destination=dst_data,\n",
    "            src_transform=src.transform,\n",
    "            dst_transform=ndvi_transform,\n",
    "            src_crs=src.crs,\n",
    "            dst_crs=ndvi_crs,\n",
    "            resampling=Resampling.bilinear\n",
    "        )\n",
    "        with rasterio.open(\n",
    "            processed_path,\n",
    "            \"w\",\n",
    "            driver=\"GTiff\",\n",
    "            height=ndvi_height,\n",
    "            width=ndvi_width,\n",
    "            count=1,\n",
    "            dtype=np.float32,\n",
    "            crs=ndvi_crs,\n",
    "            transform=ndvi_transform,\n",
    "            nodata=src.nodata\n",
    "        ) as dst:\n",
    "            dst.write(dst_data, 1)\n",
    "    print(f\"Resampled {raw_path.name} → {processed_path}\")\n",
    "\n",
    "# Example usage:\n",
    "soil_params = {\n",
    "    \"silt\": \"tadla_silt_processed.tif\",\n",
    "    \"sand\": \"tadla_sand_processed.tif\",\n",
    "    \"ocd\": \"tadla_ocd_processed.tif\",  # Organic carbon density\n",
    "    \"wv0010\": \"tadla_wv0010_processed.tif\"   # Water content at saturation\n",
    "}\n",
    "\n",
    "for param, filename in soil_params.items():\n",
    "    pre_processed_path = soil_processed_dir / filename\n",
    "    processed_path_10m = soil_processed_dir / f\"tadla_{param}_10m.tif\"\n",
    "    resample_soil_layer(pre_processed_path, processed_path_10m, ndvi_transform, ndvi_crs, ndvi_height, ndvi_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in [\"silt\", \"sand\", \"ocd\", \"wv0010\"]:\n",
    "    with rasterio.open(soil_processed_dir / f\"tadla_{param}_10m.tif\") as src:\n",
    "        print(f\"{param} resolution: {src.res}, CRS: {src.crs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resample DEM (12.5m → 10m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths (update with your actual paths)\n",
    "dem_raw = raw_data_dir / config[\"paths\"][\"dem_raw\"]\n",
    "dem_processed = processed_data_dir / config[\"paths\"][\"dem_processed\"]\n",
    "\n",
    "with rasterio.open(dem_raw) as src:\n",
    "    dst_data = np.zeros((ndvi_height, ndvi_width), dtype=np.float32)\n",
    "    reproject(\n",
    "        source=rasterio.band(src, 1),\n",
    "        destination=dst_data,\n",
    "        src_transform=src.transform,\n",
    "        dst_transform=ndvi_transform,\n",
    "        src_crs=src.crs,\n",
    "        dst_crs=ndvi_crs,\n",
    "        resampling=Resampling.bilinear  # Use cubic for elevation\n",
    "    )\n",
    "    with rasterio.open(\n",
    "        dem_processed,\n",
    "        \"w\",\n",
    "        driver=\"GTiff\",\n",
    "        height=ndvi_height,\n",
    "        width=ndvi_width,\n",
    "        count=1,\n",
    "        dtype=np.float32,\n",
    "        crs=ndvi_crs,\n",
    "        transform=ndvi_transform,\n",
    "        nodata=src.nodata\n",
    "    ) as dst:\n",
    "        dst.write(dst_data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(dem_processed) as src:\n",
    "    print(f\"DEM resolution: {src.res}, CRS: {src.crs}\")  # Should be (10.0, 10.0), EPSG:26191"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Align All Rasters to NDVI Grid\n",
    "    \n",
    "    Goal: Ensure all datasets (soil, DEM, weather) are spatially aligned with the NDVI grid.\n",
    "    Why: Even minor misalignments will break ML models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Align Weather Data (CHIRPS Rainfall and ERA5 Evaporation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
