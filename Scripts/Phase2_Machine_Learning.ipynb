{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: Soil Moisture Prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Prepare Training Data\n",
    "\n",
    "    We’ll include all features to maximize model accuracy:\n",
    "        \n",
    "##### 1. Static Features (do not change over time):\n",
    "            \n",
    "    Soil properties: clay, silt, sand, ocd (organic carbon density), wv0010 (water content at saturation).\n",
    "    Topography: DEM, slope, aspect.\n",
    "    Dynamic Features (vary monthly):\n",
    "\n",
    "##### 2. Weather: CHIRPS (rainfall), ERA5 (evaporation).\n",
    "    \n",
    "    Vegetation: NDVI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import geopandas as gpd\n",
    "import earthpy.plot as ep\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import json\n",
    "\n",
    "# Set seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Load config.yml\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Get project root (adjust based on your folder depth)\n",
    "current_dir = Path(os.getcwd())\n",
    "project_root = current_dir.parent\n",
    "with open(project_root / \"config.yml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Construct paths\n",
    "# -----------------------------------------------------------------------------\n",
    "processed_dir = project_root / Path(config['paths']['processed_data'])\n",
    "soil_dir = processed_dir / \"GIS/Soil\" # Soil data directory: clay, sand, silt, ocd, wv0110\n",
    "dem_path = processed_dir / \"GIS/Topography/tadla_dem_10m.tif\" \n",
    "slope_path = processed_dir / \"GIS/Topography/tadla_slope.tif\"\n",
    "aspect_path = processed_dir / \"GIS/Topography/tadla_aspect.tif\"\n",
    "rainfall_dir = processed_dir / \"Weather/CHIRPS_Annual\" # Rainfall data directory: chirps from 2017 to 2023, 1 file per year with 12 bands\n",
    "evapotranspiration_dir = processed_dir / \"Weather/ERA5_Annual\" # Evapotranspiration data directory: era5 from 2017 to 2023, 1 file per year with 12 bands\n",
    "boundaries_dir = processed_dir / \"GIS/Study_Area_Boundary\" \n",
    "ndvi_dir = processed_dir / \"GIS/Land_Use\" # NDVI data directory: ndvi from 2017 to 2023, 1 file per year with 12 bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load static features (soil + topography)\n",
    "static_data = {\n",
    "    \"clay\": rxr.open_rasterio(Path(soil_dir / \"tadla_clay_10m.tif\")).squeeze(),\n",
    "    \"silt\": rxr.open_rasterio(Path(soil_dir / \"tadla_silt_10m.tif\")).squeeze(),\n",
    "    \"sand\": rxr.open_rasterio(Path(soil_dir / \"tadla_sand_10m.tif\")).squeeze(),\n",
    "    \"ocd\": rxr.open_rasterio(Path(soil_dir / \"tadla_ocd_10m.tif\")).squeeze(),\n",
    "    \"wv0010\": rxr.open_rasterio(Path(soil_dir / \"tadla_wv0010_10m.tif\")).squeeze(),\n",
    "    \"dem\": rxr.open_rasterio(Path(dem_path)).squeeze(),\n",
    "    \"slope\": rxr.open_rasterio(Path(slope_path)).squeeze(),\n",
    "    \"aspect\": rxr.open_rasterio(Path(aspect_path)).squeeze(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "\n",
    "# globally set these defaults\n",
    "dask.config.set({\n",
    "    \"distributed.worker.memory.target\": 0.6,\n",
    "    \"distributed.worker.memory.spill\":  0.7,\n",
    "    \"distributed.worker.memory.pause\":  0.8,\n",
    "})\n",
    "\n",
    "from dask.distributed import Client\n",
    "client = Client(memory_limit=\"15GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# GDAL_CACHEMAX is in megabytes.  2048 MB = 2 GB.\n",
    "os.environ['GDAL_CACHEMAX'] = '2048'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_annual_data(\n",
    "    variable: str,\n",
    "    years=range(2017, 2024),\n",
    "    per_file_chunks={'band': 1, 'x': 1024, 'y': 1024},\n",
    "    final_chunks={'time': 1, 'x': 1024, 'y': 1024},\n",
    ") -> xr.DataArray:\n",
    "    \n",
    "    da_list = []\n",
    "\n",
    "    for year in years:\n",
    "        # Construct file paths based on variable\n",
    "        if variable == \"NDVI\":\n",
    "            path = ndvi_dir / f\"Sentinel2_Tadla_NDVI_{year}.tif\"\n",
    "        elif variable == \"CHIRPS\":\n",
    "            path = rainfall_dir / f\"CHIRPS_{year}_reproj.tif\"\n",
    "        elif variable == \"ERA5\":\n",
    "            path = evapotranspiration_dir / f\"ERA5_{year}_reproj.tif\"\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown variable: {variable!r}\")\n",
    "\n",
    "        # 1-band × spatial chunks, lazy disk reads:\n",
    "        da = rxr.open_rasterio(path, masked=True, chunks=per_file_chunks)\n",
    "\n",
    "        # assign a proper time index (12 months → 12 timestamps):\n",
    "        times = pd.date_range(start=f\"{year}-01-01\", periods=12, freq=\"MS\")\n",
    "        da = da.assign_coords(band=times).rename({\"band\": \"time\"})\n",
    "\n",
    "        da_list.append(da)\n",
    "\n",
    "    # concatenate into one DataArray and rechunk on 'time':\n",
    "    combined = xr.concat(da_list, dim=\"time\")\n",
    "    return combined.chunk(final_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all dynamic variables\n",
    "ndvi = load_annual_data(\"NDVI\")        # Shape: (time=84, y, x)\n",
    "chirps = load_annual_data(\"CHIRPS\")    # 84 months (7 years * 12)\n",
    "era5 = load_annual_data(\"ERA5\")        # 84 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chirps = load_annual_data(\"CHIRPS\").rename(\"precipitation\")    # 84 months (7 years * 12)\n",
    "era5 = load_annual_data(\"ERA5\").rename(\"evaporation\")       # 84 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For NDVI\n",
    "print(ndvi)\n",
    "# Output should show:\n",
    "# - Dimensions: (time: 84, y: ..., x: ...)\n",
    "# - Coordinates: time, x, y\n",
    "# - Data variables: band 1\n",
    "\n",
    "# For CHIRPS\n",
    "print(chirps)\n",
    "# Similar structure but variable name \"precipitation\"\n",
    "\n",
    "# For ERA5\n",
    "print(era5)\n",
    "# Variable name \"total_evaporation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi.attrs[\"long_name\"] = \"NDVI\"\n",
    "chirps.attrs[\"long_name\"] = \"precipitation\"\n",
    "era5.attrs[\"long_name\"] = \"total_evaporation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ndvi.rio.crs)  # Should output \"EPSG:26191\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NDVI Time Range:\", ndvi.time.min().values, \"to\", ndvi.time.max().values)\n",
    "# Should output: 2017-01-01 to 2023-12-01\n",
    "\n",
    "print(\"Number of Timesteps:\", len(ndvi.time))\n",
    "# Should output: 84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if x/y coordinates match between datasets\n",
    "x_mismatch = (ndvi.x != chirps.x).any() or (ndvi.x != era5.x).any()\n",
    "y_mismatch = (ndvi.y != chirps.y).any() or (ndvi.y != era5.y).any()\n",
    "print(f\"Spatial Mismatch: X={x_mismatch}, Y={y_mismatch}\")\n",
    "# Should output: Spatial Mismatch: X=False, Y=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spot_check(da, year, month_idx):\n",
    "    \"\"\"Check a small subset for a specific year and month.\"\"\"\n",
    "    time_idx = (year - 2017) * 12 + month_idx\n",
    "    subset = da.isel(\n",
    "        time=time_idx,\n",
    "        x=slice(5000, 5100),  # Adjust to your region of interest\n",
    "        y=slice(5000, 5100)\n",
    "    ).compute()\n",
    "    return subset.min().item(), subset.max().item()\n",
    "\n",
    "# Check NDVI for January 2017\n",
    "ndvi_min, ndvi_max = spot_check(ndvi, 2017, 0)\n",
    "print(f\"NDVI 2017-01: Min={ndvi_min}, Max={ndvi_max} (Expected: ~-0.2 to 0.9)\")\n",
    "\n",
    "# Check CHIRPS for July 2020\n",
    "chirps_min, chirps_max = spot_check(chirps, 2020, 6)\n",
    "print(f\"CHIRPS 2020-07: Min={chirps_min}, Max={chirps_max} (Expected: ≥0 mm)\")\n",
    "\n",
    "# Check ERA5 for December 2023\n",
    "era5_min, era5_max = spot_check(era5, 2023, 11)\n",
    "print(f\"ERA5 2023-12: Min={era5_min}, Max={era5_max} (Expected: ≥0 mm)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_nodata(da, x=1000, y=1000):\n",
    "    \"\"\"Check if a known NoData pixel is -9999.\"\"\"\n",
    "    return da.isel(x=x, y=y).min().compute().item() == -9999\n",
    "\n",
    "print(\"NDVI NoData Valid:\", check_nodata(ndvi))\n",
    "print(\"CHIRPS NoData Valid:\", check_nodata(chirps))\n",
    "print(\"ERA5 NoData Valid:\", check_nodata(era5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NDVI Chunks:\", ndvi.chunks)\n",
    "# Expected: Time=1, X=1024, Y=1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate expected monthly timestamps\n",
    "expected_times = pd.date_range(\"2017-01-01\", \"2023-12-01\", freq=\"MS\")\n",
    "missing_times = expected_times.difference(ndvi.time.values)\n",
    "print(f\"Missing Timesteps: {len(missing_times)}\")\n",
    "# Should output: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi.isel(time=0, x=slice(5000, 6000), y=slice(5000, 6000)).plot.imshow()\n",
    "plt.title(\"NDVI - Jan 2017 (Subset)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# Function to load annual files with time coordinates\n",
    "# --------------------------------------------------\n",
    "def load_annual_data(variable, years=range(2017, 2024)):\n",
    "    \"\"\"Load annual files with 12 bands (Jan-Dec) and assign time coordinates.\"\"\"\n",
    "    da_list = []\n",
    "    \n",
    "    for year in years:\n",
    "        # Construct file paths based on variable\n",
    "        if variable == \"NDVI\":\n",
    "            path = ndvi_dir / f\"Sentinel2_Tadla_NDVI_{year}.tif\"\n",
    "        elif variable == \"CHIRPS\":\n",
    "            path = rainfall_dir / f\"CHIRPS_{year}_reproj.tif\"\n",
    "        elif variable == \"ERA5\":\n",
    "            path = evapotranspiration_dir / f\"ERA5_{year}_reproj.tif\"\n",
    "        \n",
    "        # Load raster (12 bands = Jan-Dec)\n",
    "        da = rxr.open_rasterio(path)\n",
    "        \n",
    "        # Generate monthly timestamps for the year\n",
    "        times = pd.date_range(start=f\"{year}-01-01\", periods=12, freq=\"MS\")\n",
    "        \n",
    "        # Assign time coordinates\n",
    "        da = da.assign_coords(band=times).rename({\"band\": \"time\"})\n",
    "        \n",
    "        da_list.append(da)\n",
    "    \n",
    "    # Combine all years into a single DataArray\n",
    "    return xr.concat(da_list, dim=\"time\")\n",
    "\n",
    "# Load all dynamic variables\n",
    "ndvi = load_annual_data(\"NDVI\")        # Shape: (time=84, y, x)\n",
    "chirps = load_annual_data(\"CHIRPS\")    # 84 months (7 years * 12)\n",
    "era5 = load_annual_data(\"ERA5\")        # 84 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Function to load annual files with Dask chunking and time coordinates\n",
    "# --------------------------------------------------\n",
    "def load_annual_data(variable, years=range(2017, 2024)):\n",
    "    \"\"\"\n",
    "    Load annual files with 12 bands (one per month) and assign monthly timestamps.\n",
    "    Uses Dask chunking to manage memory when working with large datasets.\n",
    "    \"\"\"\n",
    "    da_list = []\n",
    "    \n",
    "    for year in years:\n",
    "        # Construct file path based on the variable name\n",
    "        if variable == \"NDVI\":\n",
    "            path = ndvi_dir / f\"Sentinel2_Tadla_NDVI_{year}.tif\"\n",
    "        elif variable == \"CHIRPS\":\n",
    "            path = rainfall_dir / f\"CHIRPS_{year}_reproj.tif\"\n",
    "        elif variable == \"ERA5\":\n",
    "            path = evapotranspiration_dir / f\"ERA5_{year}_reproj.tif\"\n",
    "        else:\n",
    "            raise ValueError(\"Unknown variable. Choose from 'NDVI', 'CHIRPS', or 'ERA5'.\")\n",
    "        \n",
    "        # Use rioxarray to open the raster with Dask chunking.\n",
    "        # Here we assume that each file has 12 bands representing the months.\n",
    "        da = rxr.open_rasterio(path, chunks={\"band\": 12})\n",
    "        \n",
    "        # Generate monthly timestamps for the given year\n",
    "        times = pd.date_range(start=f\"{year}-01-01\", periods=12, freq=\"MS\")\n",
    "        \n",
    "        # Assign time coordinates and rename the 'band' dimension to 'time'\n",
    "        da = da.assign_coords(band=times).rename({\"band\": \"time\"})\n",
    "        \n",
    "        da_list.append(da)\n",
    "    \n",
    "    # Concatenate all years' DataArrays along the time dimension\n",
    "    return xr.concat(da_list, dim=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dynamic features (time-series)\n",
    "dynamic_data = {\n",
    "    \"ndvi\": rxr.open_rasterio(Path(config[\"paths\"][\"ndvi_raw\"])),\n",
    "    \"chirps\": rxr.open_rasterio(Path(config[\"paths\"][\"chirps_processed\"])),\n",
    "    \"era5\": rxr.open_rasterio(Path(config[\"paths\"][\"era5_processed\"])),\n",
    "}\n",
    "\n",
    "# Combine into a single xarray Dataset\n",
    "dataset = xr.Dataset({**static_data, **dynamic_data}).to_array(dim=\"band\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
