{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: Soil Moisture Prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Prepare Training Data\n",
    "\n",
    "    We’ll include all features to maximize model accuracy:\n",
    "        \n",
    "##### 1. Static Features (do not change over time):\n",
    "            \n",
    "    Soil properties: clay, silt, sand, ocd (organic carbon density), wv0010 (water content at saturation).\n",
    "    Topography: DEM, slope, aspect.\n",
    "    Dynamic Features (vary monthly):\n",
    "\n",
    "##### 2. Weather: CHIRPS (rainfall), ERA5 (evaporation).\n",
    "    \n",
    "    Vegetation: NDVI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import geopandas as gpd\n",
    "import earthpy.plot as ep\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import json\n",
    "\n",
    "# Set seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Load config.yml\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Get project root (adjust based on your folder depth)\n",
    "current_dir = Path(os.getcwd())\n",
    "project_root = current_dir.parent\n",
    "with open(project_root / \"config.yml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Construct paths\n",
    "# -----------------------------------------------------------------------------\n",
    "processed_dir = project_root / Path(config['paths']['processed_data'])\n",
    "soil_dir = processed_dir / \"GIS/Soil\" # Soil data directory: clay, sand, silt, ocd, wv0110\n",
    "dem_path = processed_dir / \"GIS/Topography/tadla_dem_10m.tif\" \n",
    "slope_path = processed_dir / \"GIS/Topography/tadla_slope.tif\"\n",
    "aspect_path = processed_dir / \"GIS/Topography/tadla_aspect.tif\"\n",
    "rainfall_dir = processed_dir / \"Weather/CHIRPS_Annual\" # Rainfall data directory: chirps from 2017 to 2023, 1 file per year with 12 bands\n",
    "evapotranspiration_dir = processed_dir / \"Weather/ERA5_Annual\" # Evapotranspiration data directory: era5 from 2017 to 2023, 1 file per year with 12 bands\n",
    "boundaries_dir = processed_dir / \"GIS/Study_Area_Boundary\" \n",
    "ndvi_dir = processed_dir / \"GIS/Land_Use\" # NDVI data directory: ndvi from 2017 to 2023, 1 file per year with 12 bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load static features (soil + topography)\n",
    "static_data = {\n",
    "    \"clay\": rxr.open_rasterio(Path(soil_dir / \"tadla_clay_10m.tif\")).squeeze(),\n",
    "    \"silt\": rxr.open_rasterio(Path(soil_dir / \"tadla_silt_10m.tif\")).squeeze(),\n",
    "    \"sand\": rxr.open_rasterio(Path(soil_dir / \"tadla_sand_10m.tif\")).squeeze(),\n",
    "    \"ocd\": rxr.open_rasterio(Path(soil_dir / \"tadla_ocd_10m.tif\")).squeeze(),\n",
    "    \"wv0010\": rxr.open_rasterio(Path(soil_dir / \"tadla_wv0010_10m.tif\")).squeeze(),\n",
    "    \"dem\": rxr.open_rasterio(Path(dem_path)).squeeze(),\n",
    "    \"slope\": rxr.open_rasterio(Path(slope_path)).squeeze(),\n",
    "    \"aspect\": rxr.open_rasterio(Path(aspect_path)).squeeze(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abdel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\distributed\\node.py:187: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 62191 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import dask\n",
    "\n",
    "# globally set these defaults\n",
    "dask.config.set({\n",
    "    \"distributed.worker.memory.target\": 0.6,\n",
    "    \"distributed.worker.memory.spill\":  0.7,\n",
    "    \"distributed.worker.memory.pause\":  0.8,\n",
    "})\n",
    "\n",
    "from dask.distributed import Client\n",
    "client = Client(memory_limit=\"15GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# GDAL_CACHEMAX is in megabytes.  2048 MB = 2 GB.\n",
    "os.environ['GDAL_CACHEMAX'] = '2048'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_annual_data(\n",
    "    variable: str,\n",
    "    years=range(2017, 2024),\n",
    "    per_file_chunks={'band': 1, 'x': 1024, 'y': 1024},\n",
    "    final_chunks={'time': 1, 'x': 1024, 'y': 1024},\n",
    ") -> xr.DataArray:\n",
    "    \n",
    "    da_list = []\n",
    "\n",
    "    for year in years:\n",
    "        # Construct file paths based on variable\n",
    "        if variable == \"NDVI\":\n",
    "            path = ndvi_dir / f\"Sentinel2_Tadla_NDVI_{year}.tif\"\n",
    "        elif variable == \"CHIRPS\":\n",
    "            path = rainfall_dir / f\"CHIRPS_{year}_reproj.tif\"\n",
    "        elif variable == \"ERA5\":\n",
    "            path = evapotranspiration_dir / f\"ERA5_{year}_reproj.tif\"\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown variable: {variable!r}\")\n",
    "\n",
    "        # 1-band × spatial chunks, lazy disk reads:\n",
    "        da = rxr.open_rasterio(path, masked=True, chunks=per_file_chunks)\n",
    "\n",
    "        # assign a proper time index (12 months → 12 timestamps):\n",
    "        times = pd.date_range(start=f\"{year}-01-01\", periods=12, freq=\"MS\")\n",
    "        da = da.assign_coords(band=times).rename({\"band\": \"time\"})\n",
    "\n",
    "        da_list.append(da)\n",
    "\n",
    "    # concatenate into one DataArray and rechunk on 'time':\n",
    "    combined = xr.concat(da_list, dim=\"time\")\n",
    "    return combined.chunk(final_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all dynamic variables\n",
    "ndvi = load_annual_data(\"NDVI\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# Function to load annual files with time coordinates\n",
    "# --------------------------------------------------\n",
    "def load_annual_data(variable, years=range(2017, 2024)):\n",
    "    \"\"\"Load annual files with 12 bands (Jan-Dec) and assign time coordinates.\"\"\"\n",
    "    da_list = []\n",
    "    \n",
    "    for year in years:\n",
    "        # Construct file paths based on variable\n",
    "        if variable == \"NDVI\":\n",
    "            path = ndvi_dir / f\"Sentinel2_Tadla_NDVI_{year}.tif\"\n",
    "        elif variable == \"CHIRPS\":\n",
    "            path = rainfall_dir / f\"CHIRPS_{year}_reproj.tif\"\n",
    "        elif variable == \"ERA5\":\n",
    "            path = evapotranspiration_dir / f\"ERA5_{year}_reproj.tif\"\n",
    "        \n",
    "        # Load raster (12 bands = Jan-Dec)\n",
    "        da = rxr.open_rasterio(path)\n",
    "        \n",
    "        # Generate monthly timestamps for the year\n",
    "        times = pd.date_range(start=f\"{year}-01-01\", periods=12, freq=\"MS\")\n",
    "        \n",
    "        # Assign time coordinates\n",
    "        da = da.assign_coords(band=times).rename({\"band\": \"time\"})\n",
    "        \n",
    "        da_list.append(da)\n",
    "    \n",
    "    # Combine all years into a single DataArray\n",
    "    return xr.concat(da_list, dim=\"time\")\n",
    "\n",
    "# Load all dynamic variables\n",
    "ndvi = load_annual_data(\"NDVI\")        # Shape: (time=84, y, x)\n",
    "chirps = load_annual_data(\"CHIRPS\")    # 84 months (7 years * 12)\n",
    "era5 = load_annual_data(\"ERA5\")        # 84 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Function to load annual files with Dask chunking and time coordinates\n",
    "# --------------------------------------------------\n",
    "def load_annual_data(variable, years=range(2017, 2024)):\n",
    "    \"\"\"\n",
    "    Load annual files with 12 bands (one per month) and assign monthly timestamps.\n",
    "    Uses Dask chunking to manage memory when working with large datasets.\n",
    "    \"\"\"\n",
    "    da_list = []\n",
    "    \n",
    "    for year in years:\n",
    "        # Construct file path based on the variable name\n",
    "        if variable == \"NDVI\":\n",
    "            path = ndvi_dir / f\"Sentinel2_Tadla_NDVI_{year}.tif\"\n",
    "        elif variable == \"CHIRPS\":\n",
    "            path = rainfall_dir / f\"CHIRPS_{year}_reproj.tif\"\n",
    "        elif variable == \"ERA5\":\n",
    "            path = evapotranspiration_dir / f\"ERA5_{year}_reproj.tif\"\n",
    "        else:\n",
    "            raise ValueError(\"Unknown variable. Choose from 'NDVI', 'CHIRPS', or 'ERA5'.\")\n",
    "        \n",
    "        # Use rioxarray to open the raster with Dask chunking.\n",
    "        # Here we assume that each file has 12 bands representing the months.\n",
    "        da = rxr.open_rasterio(path, chunks={\"band\": 12})\n",
    "        \n",
    "        # Generate monthly timestamps for the given year\n",
    "        times = pd.date_range(start=f\"{year}-01-01\", periods=12, freq=\"MS\")\n",
    "        \n",
    "        # Assign time coordinates and rename the 'band' dimension to 'time'\n",
    "        da = da.assign_coords(band=times).rename({\"band\": \"time\"})\n",
    "        \n",
    "        da_list.append(da)\n",
    "    \n",
    "    # Concatenate all years' DataArrays along the time dimension\n",
    "    return xr.concat(da_list, dim=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dynamic features (time-series)\n",
    "dynamic_data = {\n",
    "    \"ndvi\": rxr.open_rasterio(Path(config[\"paths\"][\"ndvi_raw\"])),\n",
    "    \"chirps\": rxr.open_rasterio(Path(config[\"paths\"][\"chirps_processed\"])),\n",
    "    \"era5\": rxr.open_rasterio(Path(config[\"paths\"][\"era5_processed\"])),\n",
    "}\n",
    "\n",
    "# Combine into a single xarray Dataset\n",
    "dataset = xr.Dataset({**static_data, **dynamic_data}).to_array(dim=\"band\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
